{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/gpfsdswork/projects/rech/ank/ucv88ce/repos/CPC_torch\")\n",
    "sys.path.insert(0, \"/gpfsdswork/projects/rech/ank/ucv88ce/repos/CPC_torch/cpc/eval\")\n",
    "sys.path.insert(0, \"/gpfsdswork/projects/rech/ank/ucv88ce/repos/CPC_torch/cpc/transformers\")\n",
    "\n",
    "sys.path.insert(0, \"/gpfsdswork/projects/rech/ank/ucv88ce/repos/WavAugment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-8c4df551bd9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_CPC_proba\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "from utils.compute_CPC_proba import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import time\n",
    "import torch\n",
    "import torchaudio\n",
    "from cpc.feature_loader import loadModel, getCheckpointData\n",
    "from cpc.train import getCriterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadCriterion(pathCheckpoint, downsampling, nSpeakers, nPhones):\n",
    "    _, _, locArgs = getCheckpointData(os.path.dirname(pathCheckpoint))\n",
    "    criterion = getCriterion(locArgs, downsampling, nSpeakers, nPhones)\n",
    "\n",
    "    state_dict = torch.load(pathCheckpoint, 'cpu')\n",
    "    \n",
    "    # for newer versions of CPC, the name is changed\n",
    "    try:\n",
    "        criterion.load_state_dict(state_dict[\"cpcCriterion\"])\n",
    "    except RuntimeError:\n",
    "        state_dict[\"cpcCriterion\"]['speakerEmb.weight'] = state_dict[\"cpcCriterion\"]['speaker_norm.emb.weight']\n",
    "        del state_dict[\"cpcCriterion\"]['speaker_norm.emb.weight']\n",
    "        criterion.load_state_dict(state_dict[\"cpcCriterion\"])\n",
    "\n",
    "    return criterion\n",
    "\n",
    "def getPositiveSamples(encodedData, nPredicts=12):\n",
    "    batchSize, nNegativeExt, dimEncoded = encodedData.size()\n",
    "    outputs = []\n",
    "    \n",
    "    for k in range(1, nPredicts + 1):\n",
    "        # Positive samples\n",
    "        if k < nPredicts:\n",
    "            posSeq = encodedData[:, k:-(nPredicts-k)]\n",
    "        else:\n",
    "            posSeq = encodedData[:, k:]\n",
    "\n",
    "        posSeq = posSeq.view(batchSize, 1, posSeq.size(1), dimEncoded)\n",
    "        outputs.append(posSeq)\n",
    "    \n",
    "    return outputs\n",
    "\n",
    "def scoring(logprobs):\n",
    "    n = len(logprobs)//2\n",
    "    true_preds = 0\n",
    "    results = []\n",
    "    for i in range(n):\n",
    "        if logprobs[2*i] > logprobs[2*i + 1]:\n",
    "            true_preds += 1\n",
    "            results.append(True)\n",
    "        else:\n",
    "            results.append(False)\n",
    "    if n != 0:\n",
    "        print(\"Test accuracy: {}/{} ({:.2f}%)\".format(true_preds, n, 100*true_preds/n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to compute proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_score_CPC(seqPath, \n",
    "                      cpcModel, \n",
    "                      cpcCriterion, \n",
    "                      speakerLabel=0,\n",
    "                      nTemporal=12,\n",
    "                      logits_scaling=1,\n",
    "                      reduce_method='sum',\n",
    "                      prob_estimator='negative_sampling',\n",
    "                      n_negative_sampling=None, score=\"accuracy\"):\n",
    "    '''\n",
    "    Comment on some useful args:\n",
    "        logits_scaling:  put this high to avoid having 0. log proba for near temporal steps when \n",
    "                         using sigmoid, but it seems that 1 (default) gives the best results\n",
    "         reduce_method:  'sum' seems to work best\n",
    "        prob_estimator:  using 'sigmoid' is faster as we don't need to compute negative samples,\n",
    "                         but using 'negative_sampling' seems to have better results as this is\n",
    "                         the way the CPC model is trained (however this will make the scores varying)\n",
    "   n_negative_sampling:  leave this to 'None' and the model will use 128(defaut) negative samples\n",
    "    score:                either [accuracy] (mean on 12 frames, in that case reduce_method is not used) or [logprob]\n",
    "    '''\n",
    "    assert reduce_method in ['sum', 'mean']\n",
    "    assert prob_estimator in ['sigmoid', 'negative_sampling']\n",
    "    with torch.no_grad():\n",
    "        # Read the input signals\n",
    "        seq = torchaudio.load(seqPath)[0] # 1 x frames\n",
    "        seq = seq[:,:].view(1, 1, -1).cuda() # 1 x 1 x frames\n",
    "        \n",
    "        # Read CPC features\n",
    "        cpcModel.gAR.hidden = None\n",
    "        cFeature, encodedData, label = cpcModel(seq, label=None)\n",
    "        ## cFeature: 1 x T x D_feat\n",
    "        ## encodedData: 1 x T x D_enc\n",
    "        \n",
    "        # Prepare CPC features for criterion\n",
    "        batchSize, seqSize, _ = cFeature.size()\n",
    "        windowSize = seqSize - cpcCriterion.nPredicts # T - 12\n",
    "        cFeature = cFeature[:, :windowSize] # 1 x (T - 12) x D_feat\n",
    "        \n",
    "        # Get positive encoded samples\n",
    "        if prob_estimator=='negative_sampling':\n",
    "            if n_negative_sampling is not None:\n",
    "                cpcCriterion.negativeSamplingExt = n_negative_sampling\n",
    "            sampledData, _ = cpcCriterion.sampleClean(encodedData, windowSize) # 12 x 1 x (1 + n_negative_sampling) x (T - 12) x D_enc\n",
    "        else:\n",
    "            sampledData = getPositiveSamples(encodedData, cpcCriterion.nPredicts) # 12 x 1 x 1 x (T - 12) x D_enc\n",
    "        \n",
    "        # Speaker embeddings\n",
    "        if cpcCriterion.speakerEmb is not None:\n",
    "            label = torch.tensor(speakerLabel).cuda()\n",
    "            l_ = label.view(batchSize, 1).expand(batchSize, windowSize) # 1 x (T - 12)\n",
    "            embeddedSpeaker = cpcCriterion.speakerEmb(l_) # 1 x (T - 12) x D_spkemb\n",
    "            cFeature = torch.cat([cFeature, embeddedSpeaker], dim=2) # 1 x (T - 12) x (D_feat+D_spkemb)\n",
    "            \n",
    "        # Compute the criterion outputs\n",
    "        predictions = cpcCriterion.wPrediction(cFeature, sampledData) # 12 x 1 x 1 x (T - 12)\n",
    "        \n",
    "        if score == \"accuracy\":\n",
    "            score = 0\n",
    "            for outputs in predictions[:nTemporal]:\n",
    "                score += outputs[0]\n",
    "            score = np.mean(np.array(score))\n",
    "            \n",
    "        \n",
    "        # Compute the pseudo log-probas\n",
    "        if score == \"logprob\":\n",
    "            lp_score = 0.\n",
    "            for outputs in predictions[:nTemporal]:\n",
    "                logits = outputs[0]/logits_scaling\n",
    "                if logits.size(0) == 1:\n",
    "                    logits = logits.sigmoid()\n",
    "                else:\n",
    "                    logits = logits.softmax(0)\n",
    "                if reduce_method == 'sum':\n",
    "                    lp_score += logits[0].log().sum()\n",
    "                elif reduce_method == 'mean':\n",
    "                    lp_score += logits[0].log().mean()\n",
    "            lp_score  /= nTemporal\n",
    "            score = lp_score.item()\n",
    "        \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CPC model and criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint /gpfsssd/scratch/rech/cfs/commun/InfTrain_models/EN/3200h/00/cpc_small/checkpoint_25.pt\n",
      "Loading checkpoint /gpfsscratch/rech/cfs/commun/InfTrain_models/EN/3200h/00/cpc_small/checkpoint_20.pt\n",
      "Loading the state dict at /gpfsssd/scratch/rech/cfs/commun/InfTrain_models/EN/3200h/00/cpc_small/checkpoint_25.pt\n",
      "Activating multi-head rnn\n",
      "CPC model and criterion loaded!\n"
     ]
    }
   ],
   "source": [
    "# Checkpoint path\n",
    "#pathCheckpoint = \"/private/home/mriviere/FairInternal/CPC_torch/Librispeech100/channel_norm_attention_dropout_2levels_multihead/checkpoint_170.pt\"\n",
    "#pathCheckpoint = \"/private/home/mriviere/FairInternal/CPC_torch/Librilight_subsample/6k_top_ctc/checkpoint_30.pt\"\n",
    "pathCheckpoint = \"/gpfsssd/scratch/rech/cfs/commun/InfTrain_models/EN/3200h/00/cpc_small/checkpoint_25.pt\"\n",
    "\n",
    "# Load CPC model\n",
    "cpcModel = loadModel([pathCheckpoint])[0].cuda()\n",
    "cpcModel.gAR.keepHidden = True\n",
    "cpcModel.eval()\n",
    "# Load CPC criterion\n",
    "cpcCriterion = loadCriterion(pathCheckpoint, cpcModel.gEncoder.DOWNSAMPLING, 7504, None).cuda()\n",
    "cpcCriterion.eval()\n",
    "print('CPC model and criterion loaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1252.8173828125"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_score_CPC(seqPath='/gpfsssd/scratch/rech/cfs/commun/cv21_ABX/raw_dataset/en/common_voice_en_16665978.wav', \n",
    "                            cpcModel=cpcModel, \n",
    "                            cpcCriterion=cpcCriterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-861.8214721679688"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_score_CPC(seqPath='/gpfsssd/scratch/rech/cfs/commun/cv21_ABX/raw_dataset/fr/common_voice_fr_17307725.wav', \n",
    "                            cpcModel=cpcModel, \n",
    "                            cpcCriterion=cpcCriterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sWUGGY dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 files found!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0_obscenely_inter_dev_final_voiceA.wav',\n",
       " '1_opsenely_inter_dev_final_voiceA.wav',\n",
       " '2_oxidation_inter_dev_final_voiceA.wav',\n",
       " '3_accidation_inter_dev_final_voiceA.wav',\n",
       " '4_alida_inter_dev_final_voiceA.wav',\n",
       " '5_aleca_inter_dev_final_voiceA.wav']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathAudio=\"/private/home/ntuanh/Projects/ZeroSpeech/data/test/sWUGGY/final/audio/synthesis_16k/inter/dev/voiceA/\"\n",
    "filelist = sorted([item for item in os.listdir(pathAudio) if item.endswith('.wav')], key = lambda x: int(x.split('_')[0]))\n",
    "print(f'{len(filelist)} files found!')\n",
    "filelist[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9901/10000 files computed in 83.15 seconds\n",
      "...done in 83.94 seconds.\n",
      "Test accuracy: 2877/5000 (57.54%)\n",
      "CPU times: user 1min 16s, sys: 1.29 s, total: 1min 17s\n",
      "Wall time: 1min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stime = time()\n",
    "scores_files = []\n",
    "for i, file in enumerate(filelist):\n",
    "    sc = compute_score_CPC(seqPath=os.path.join(pathAudio, file), \n",
    "                            cpcModel=cpcModel, \n",
    "                            cpcCriterion=cpcCriterion)\n",
    "    scores_files.append(sc)\n",
    "    if i % 100 == 0:\n",
    "        print(f'{i+1}/{len(filelist)} files computed in {time()-stime:.2f} seconds', end = '\\r')\n",
    "print(f'\\n...done in {time()-stime:.2f} seconds.')\n",
    "scoring(scores_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### text-WUGGY set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000 files found!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0_aback.wav',\n",
       " '1_aball.wav',\n",
       " '2_abandon.wav',\n",
       " '3_agandon.wav',\n",
       " '4_abandoning.wav',\n",
       " '5_afandoning.wav']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathAudio=\"/private/home/ntuanh/Projects/ZeroSpeech/data/test/WUGGY-text/devLS_10k/audio/wavs-16k/\"\n",
    "filelist = sorted([item for item in os.listdir(pathAudio) if item.endswith('.wav')], key = lambda x: int(x.split('_')[0]))\n",
    "print(f'{len(filelist)} files found!')\n",
    "filelist[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19901/20000 files computed in 165.93 seconds\n",
      "...done in 166.74 seconds.\n",
      "Test accuracy: 6002/10000 (60.02%)\n",
      "CPU times: user 2min 36s, sys: 2.02 s, total: 2min 38s\n",
      "Wall time: 2min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stime = time()\n",
    "scores_files = []\n",
    "for i, file in enumerate(filelist):\n",
    "    sc = compute_score_CPC(seqPath=os.path.join(pathAudio, file), \n",
    "                            cpcModel=cpcModel, \n",
    "                            cpcCriterion=cpcCriterion)\n",
    "    scores_files.append(sc)\n",
    "    if i % 100 == 0:\n",
    "        print(f'{i+1}/{len(filelist)} files computed in {time()-stime:.2f} seconds', end = '\\r')\n",
    "print(f'\\n...done in {time()-stime:.2f} seconds.')\n",
    "scoring(scores_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
