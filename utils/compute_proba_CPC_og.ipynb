{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80b8f1a8-20f0-4195-8821-5a4cdafc8f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import time\n",
    "import torch\n",
    "import torchaudio\n",
    "from cpc.feature_loader import loadModel, getCheckpointData\n",
    "from cpc.train import getCriterion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fde6231-5105-47a0-b379-9918b621704c",
   "metadata": {},
   "source": [
    "## Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1aa59ea7-ce0d-4b54-91b8-661a48f9a105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadCriterion(pathCheckpoint, downsampling, nSpeakers, nPhones):\n",
    "    _, _, locArgs = getCheckpointData(os.path.dirname(pathCheckpoint))\n",
    "    criterion = getCriterion(locArgs, downsampling, nSpeakers, nPhones)\n",
    "\n",
    "    state_dict = torch.load(pathCheckpoint, 'cpu')\n",
    "    \n",
    "    # for newer versions of CPC, the name is changed\n",
    "    try:\n",
    "        criterion.load_state_dict(state_dict[\"cpcCriterion\"])\n",
    "    except RuntimeError:\n",
    "        state_dict[\"cpcCriterion\"]['speakerEmb.weight'] = state_dict[\"cpcCriterion\"]['speaker_norm.emb.weight']\n",
    "        del state_dict[\"cpcCriterion\"]['speaker_norm.emb.weight']\n",
    "        criterion.load_state_dict(state_dict[\"cpcCriterion\"])\n",
    "\n",
    "    return criterion\n",
    "\n",
    "def getPositiveSamples(encodedData, nPredicts=12):\n",
    "    batchSize, nNegativeExt, dimEncoded = encodedData.size()\n",
    "    outputs = []\n",
    "    \n",
    "    for k in range(1, nPredicts + 1):\n",
    "        # Positive samples\n",
    "        if k < nPredicts:\n",
    "            posSeq = encodedData[:, k:-(nPredicts-k)]\n",
    "        else:\n",
    "            posSeq = encodedData[:, k:]\n",
    "\n",
    "        posSeq = posSeq.view(batchSize, 1, posSeq.size(1), dimEncoded)\n",
    "        outputs.append(posSeq)\n",
    "    \n",
    "    return outputs\n",
    "\n",
    "def scoring(logprobs):\n",
    "    n = len(logprobs)//2\n",
    "    true_preds = 0\n",
    "    results = []\n",
    "    for i in range(n):\n",
    "        if logprobs[2*i] > logprobs[2*i + 1]:\n",
    "            true_preds += 1\n",
    "            results.append(True)\n",
    "        else:\n",
    "            results.append(False)\n",
    "    if n != 0:\n",
    "        print(\"Test accuracy: {}/{} ({:.2f}%)\".format(true_preds, n, 100*true_preds/n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a869f928-dbfd-4dcf-876d-4966f2c688d6",
   "metadata": {},
   "source": [
    "## Function to compute proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "251db97a-134f-4e18-9956-0fcd2568f8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_score_CPC(seqPath, \n",
    "                      cpcModel, \n",
    "                      cpcCriterion, \n",
    "                      speakerLabel=0,\n",
    "                      nTemporal=12,\n",
    "                      logits_scaling=1,\n",
    "                      reduce_method='sum',\n",
    "                      prob_estimator='negative_sampling',\n",
    "                      n_negative_sampling=None\n",
    "                     ):\n",
    "    '''\n",
    "    Comment on some useful args:\n",
    "        logits_scaling:  put this high to avoid having 0. log proba for near temporal steps when \n",
    "                         using sigmoid, but it seems that 1 (default) gives the best results\n",
    "         reduce_method:  'sum' seems to work best\n",
    "        prob_estimator:  using 'sigmoid' is faster as we don't need to compute negative samples,\n",
    "                         but using 'negative_sampling' seems to have better results as this is\n",
    "                         the way the CPC model is trained (however this will make the scores varying)\n",
    "   n_negative_sampling:  leave this to 'None' and the model will use 128(defaut) negative samples\n",
    "    '''\n",
    "    assert reduce_method in ['sum', 'mean']\n",
    "    assert prob_estimator in ['sigmoid', 'negative_sampling']\n",
    "    with torch.no_grad():\n",
    "        # Read the input signals\n",
    "        seq = torchaudio.load(seqPath)[0] # 1 x frames\n",
    "        seq = seq[:,:].view(1, 1, -1).cuda() # 1 x 1 x frames\n",
    "        \n",
    "        # Read CPC features\n",
    "        cpcModel.gAR.hidden = None\n",
    "        cFeature, encodedData, label = cpcModel(seq, label=None)\n",
    "        ## cFeature: 1 x T x D_feat\n",
    "        ## encodedData: 1 x T x D_enc\n",
    "        \n",
    "        # Prepare CPC features for criterion\n",
    "        batchSize, seqSize, _ = cFeature.size()\n",
    "        windowSize = seqSize - cpcCriterion.nPredicts # T - 12\n",
    "        cFeature = cFeature[:, :windowSize] # 1 x (T - 12) x D_feat\n",
    "        \n",
    "        # Get positive encoded samples\n",
    "        if prob_estimator=='negative_sampling':\n",
    "            if n_negative_sampling is not None:\n",
    "                cpcCriterion.negativeSamplingExt = n_negative_sampling\n",
    "            sampledData, _ = cpcCriterion.sampleClean(encodedData, windowSize) # 12 x 1 x (1 + n_negative_sampling) x (T - 12) x D_enc\n",
    "        else:\n",
    "            sampledData = getPositiveSamples(encodedData, cpcCriterion.nPredicts) # 12 x 1 x 1 x (T - 12) x D_enc\n",
    "        \n",
    "        # Speaker embeddings\n",
    "        if cpcCriterion.speakerEmb is not None:\n",
    "            label = torch.tensor(speakerLabel).cuda()\n",
    "            l_ = label.view(batchSize, 1).expand(batchSize, windowSize) # 1 x (T - 12)\n",
    "            embeddedSpeaker = cpcCriterion.speakerEmb(l_) # 1 x (T - 12) x D_spkemb\n",
    "            cFeature = torch.cat([cFeature, embeddedSpeaker], dim=2) # 1 x (T - 12) x (D_feat+D_spkemb)\n",
    "            \n",
    "        # Compute the criterion outputs\n",
    "        predictions = cpcCriterion.wPrediction(cFeature, sampledData) # 12 x 1 x 1 x (T - 12)\n",
    "        \n",
    "        # Compute the pseudo log-probas\n",
    "        lp_score = 0.\n",
    "        for outputs in predictions[:nTemporal]:\n",
    "            logits = outputs[0]/logits_scaling\n",
    "            if logits.size(0) == 1:\n",
    "                logits = logits.sigmoid()\n",
    "            else:\n",
    "                logits = logits.softmax(0)\n",
    "            if reduce_method == 'sum':\n",
    "                lp_score += logits[0].log().sum()\n",
    "            elif reduce_method == 'mean':\n",
    "                lp_score += logits[0].log().mean()\n",
    "        lp_score  /= nTemporal\n",
    "        \n",
    "    return lp_score.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9582981d-6c01-43c3-a538-70728c40cb01",
   "metadata": {},
   "source": [
    "## Load CPC model and criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84f2f12a-227f-4554-9445-7a22f9172efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint /private/home/mriviere/FairInternal/CPC_torch/Librilight_subsample/6k_top_ctc/checkpoint_30.pt\n",
      "Loading the state dict at /private/home/mriviere/FairInternal/CPC_torch/Librilight_subsample/6k_top_ctc/checkpoint_30.pt\n",
      "Using 6 speaker embeddings for 7504 speakers\n",
      "Activating multi-head rnn\n",
      "CPC model and criterion loaded!\n"
     ]
    }
   ],
   "source": [
    "# Checkpoint path\n",
    "#pathCheckpoint = \"/private/home/mriviere/FairInternal/CPC_torch/Librispeech100/channel_norm_attention_dropout_2levels_multihead/checkpoint_170.pt\"\n",
    "pathCheckpoint = \"/private/home/mriviere/FairInternal/CPC_torch/Librilight_subsample/6k_top_ctc/checkpoint_30.pt\"\n",
    "# Load CPC model\n",
    "cpcModel = loadModel([pathCheckpoint])[0].cuda()\n",
    "cpcModel.gAR.keepHidden = True\n",
    "cpcModel.eval()\n",
    "# Load CPC criterion\n",
    "cpcCriterion = loadCriterion(pathCheckpoint, cpcModel.gEncoder.DOWNSAMPLING, 7504, None).cuda()\n",
    "cpcCriterion.eval()\n",
    "print('CPC model and criterion loaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3de652-7264-408d-af69-ecdca7521472",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "996765a0-ea79-492f-b5d6-bc01ebd54825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-232.22927856445312"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_score_CPC(seqPath='/private/home/ntuanh/Projects/ZeroSpeech/data/test/sWUGGY/final/audio/synthesis_16k/inter/dev/voiceA/0_obscenely_inter_dev_final_voiceA.wav', \n",
    "                            cpcModel=cpcModel, \n",
    "                            cpcCriterion=cpcCriterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e805688-88fe-476c-9be5-a67e3f8910f7",
   "metadata": {},
   "source": [
    "### sWUGGY dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2bb4ddf-5229-431d-8da1-978bb3d0f0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 files found!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0_obscenely_inter_dev_final_voiceA.wav',\n",
       " '1_opsenely_inter_dev_final_voiceA.wav',\n",
       " '2_oxidation_inter_dev_final_voiceA.wav',\n",
       " '3_accidation_inter_dev_final_voiceA.wav',\n",
       " '4_alida_inter_dev_final_voiceA.wav',\n",
       " '5_aleca_inter_dev_final_voiceA.wav']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathAudio=\"/private/home/ntuanh/Projects/ZeroSpeech/data/test/sWUGGY/final/audio/synthesis_16k/inter/dev/voiceA/\"\n",
    "filelist = sorted([item for item in os.listdir(pathAudio) if item.endswith('.wav')], key = lambda x: int(x.split('_')[0]))\n",
    "print(f'{len(filelist)} files found!')\n",
    "filelist[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b77c279-a036-4160-a3b5-d7139db482f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9901/10000 files computed in 83.15 seconds\n",
      "...done in 83.94 seconds.\n",
      "Test accuracy: 2877/5000 (57.54%)\n",
      "CPU times: user 1min 16s, sys: 1.29 s, total: 1min 17s\n",
      "Wall time: 1min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stime = time()\n",
    "scores_files = []\n",
    "for i, file in enumerate(filelist):\n",
    "    sc = compute_score_CPC(seqPath=os.path.join(pathAudio, file), \n",
    "                            cpcModel=cpcModel, \n",
    "                            cpcCriterion=cpcCriterion)\n",
    "    scores_files.append(sc)\n",
    "    if i % 100 == 0:\n",
    "        print(f'{i+1}/{len(filelist)} files computed in {time()-stime:.2f} seconds', end = '\\r')\n",
    "print(f'\\n...done in {time()-stime:.2f} seconds.')\n",
    "scoring(scores_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39e83ff-dffb-414a-b9e2-f191a4168299",
   "metadata": {},
   "source": [
    "### text-WUGGY set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "370924fd-1cf8-40c7-a4da-8289a54ba444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000 files found!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0_aback.wav',\n",
       " '1_aball.wav',\n",
       " '2_abandon.wav',\n",
       " '3_agandon.wav',\n",
       " '4_abandoning.wav',\n",
       " '5_afandoning.wav']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathAudio=\"/private/home/ntuanh/Projects/ZeroSpeech/data/test/WUGGY-text/devLS_10k/audio/wavs-16k/\"\n",
    "filelist = sorted([item for item in os.listdir(pathAudio) if item.endswith('.wav')], key = lambda x: int(x.split('_')[0]))\n",
    "print(f'{len(filelist)} files found!')\n",
    "filelist[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4dfe8e0f-640c-4f31-bed7-732c5780b031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19901/20000 files computed in 165.93 seconds\n",
      "...done in 166.74 seconds.\n",
      "Test accuracy: 6002/10000 (60.02%)\n",
      "CPU times: user 2min 36s, sys: 2.02 s, total: 2min 38s\n",
      "Wall time: 2min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stime = time()\n",
    "scores_files = []\n",
    "for i, file in enumerate(filelist):\n",
    "    sc = compute_score_CPC(seqPath=os.path.join(pathAudio, file), \n",
    "                            cpcModel=cpcModel, \n",
    "                            cpcCriterion=cpcCriterion)\n",
    "    scores_files.append(sc)\n",
    "    if i % 100 == 0:\n",
    "        print(f'{i+1}/{len(filelist)} files computed in {time()-stime:.2f} seconds', end = '\\r')\n",
    "print(f'\\n...done in {time()-stime:.2f} seconds.')\n",
    "scoring(scores_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dbd6f4-61b0-496f-b8aa-7f98a0263267",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
